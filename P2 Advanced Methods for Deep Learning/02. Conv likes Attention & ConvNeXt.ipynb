{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0b9716-c7f0-481d-8544-2060bdae36ae",
   "metadata": {},
   "source": [
    "# Conv likes Attention & ConvNeXt\n",
    "\n",
    "In the previous chapter, we revisited the strengths and weaknesses of convolutions and attention mechanisms. We introduced CoAtNet, a model that synergistically combines these two paradigms to leverage their strengths. In this chapter, we'll explore ConvNeXt, a novel approach that reimagines convolutional neural networks (CNNs) by adopting the design principles of Vision Transformers (ViTs). ConvNeXt has demonstrated remarkable performance, showing that convolutions can still be highly competitive in the modern deep learning landscape.\n",
    "\n",
    "## Introduction to ConvNeXt\n",
    "\n",
    "![ConvNeXt](../imgs/ConvNeXt.jpg)\n",
    "\n",
    "ConvNeXt, is a family of convolutional neural networks designed to bridge the gap between traditional CNNs and ViTs. By incorporating key architectural innovations inspired by ViTs, ConvNeXt models achieve competitive performance while maintaining the efficiency and simplicity of convolutions.\n",
    "\n",
    "## Key Innovations in ConvNeXt\n",
    "\n",
    "### 1. Layer Normalization and GELU Activation\n",
    "ConvNeXt replaces traditional batch normalization with layer normalization. This change aligns with ViTs' use of layer normalization, which has been shown to stabilize training and improve performance. Additionally, ConvNeXt employs the Gaussian Error Linear Unit (GELU) activation function, further enhancing non-linearity and gradient flow.\n",
    "\n",
    "### 2. Depthwise Convolutions\n",
    "Depthwise convolutions are utilized extensively in ConvNeXt. These convolutions reduce computational complexity by splitting the convolution operation into a depthwise convolution followed by a pointwise convolution. This approach is reminiscent of the depthwise separable convolutions used in MobileNets.\n",
    "\n",
    "### 3. Large Kernel Sizes\n",
    "Inspired by the global receptive field of self-attention in ViTs, ConvNeXt employs large kernel sizes in its convolutions. This design choice enables the network to capture long-range dependencies more effectively, bridging the gap between local convolutions and global self-attention mechanisms.\n",
    "\n",
    "### 4. ConvNeXt Block\n",
    "The ConvNeXt block is the fundamental building block of the model. It consists of a series of operations that incorporate the aforementioned innovations.\n",
    "\n",
    "### 5. Macro Architecture\n",
    "ConvNeXt follows a hierarchical design, similar to traditional CNNs. It consists of several stages, each reducing the spatial dimensions while increasing the feature dimensions. This design maintains the efficiency of CNNs while incorporating the benefits of ViTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3f5cf4-5fc1-492b-a60a-5f7ab5143c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\bdl\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\bdl\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "D:\\Anaconda\\envs\\bdl\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1000])\n",
      "ConvNeXt(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        # self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim)\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n",
    "\n",
    "class ConvNeXt(nn.Module):\n",
    "    def __init__(self, in_chans=3, num_classes=1000, depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., layer_scale_init_value=1e-6, head_init_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=1, padding=1),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList()\n",
    "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-2, -1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape,)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "model = ConvNeXt()\n",
    "input_tensor = torch.randn(8, 3, 224, 224)  # Batch of 8, 3x224x224 images\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # Should output torch.Size([8, 1000])\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl",
   "language": "python",
   "name": "bdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
