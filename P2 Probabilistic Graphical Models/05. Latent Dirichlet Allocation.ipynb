{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c464785",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12700e61-faf1-4d34-8273-f4a2e2ad3092",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation(LDA) is a generative probability model used for text analysis, aimed at discovering hidden topics from a large number of documents. It assumes that each document is generated by a mixture of several topics, and each topic is a distribution of several words. The basic idea of LDA is to represent the vocabulary structure in a document set as a collection of topics, and to reveal these hidden topics by analyzing the distribution of words in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d550a8-7d80-4d49-b5d2-c0968eac745e",
   "metadata": {},
   "source": [
    "## The generation process of LDA\n",
    "\n",
    "**1. Prior distribution**:\n",
    "- The topic distribution of each document follows a Dirichlet distribution.\n",
    "- The word distribution of each topic also follows a Dirichlet distribution.\n",
    "\n",
    "**2. Generation steps**:\n",
    "\n",
    "- For each document:\n",
    "  - Extracting the Topic Distribution of Documents from the Dirichlet Distribution.\n",
    "  - For each word in the document:\n",
    "    - Extracting a Topic from the Topic Distribution of a Document.\n",
    "    - Extract a word from the word distribution of the selected topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d147c-3a28-4cea-8422-26ecb1b10cbc",
   "metadata": {},
   "source": [
    "The following is an example of implementing an LDA model using Python and the Gensim library. Gensim is a library used for natural language processing, particularly adept at handling large-scale text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94036ac1-094d-4be7-8e4f-e48ed5c0c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n",
      "\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(2, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(4, 1), (10, 1), (12, 1), (13, 1), (14, 1)], [(3, 1), (10, 2), (13, 1), (15, 1), (16, 1)], [(8, 1), (11, 1), (12, 1), (17, 1), (18, 1), (19, 1), (20, 1)], [(21, 1), (22, 1), (23, 1), (24, 1), (25, 1)], [(24, 1), (26, 1), (27, 1), (28, 1)], [(24, 1), (26, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)], [(9, 1), (26, 1), (30, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaModel\n",
    "import string\n",
    "\n",
    "stop_words = set([\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "    \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n",
    "    \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\",\n",
    "    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n",
    "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\n",
    "    \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\",\n",
    "    \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\",\n",
    "    \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n",
    "    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\",\n",
    "    \"should\", \"now\"\n",
    "])\n",
    "\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\"\n",
    "]\n",
    "\n",
    "texts = [\n",
    "    [word for word in doc.lower().split() if word.isalnum() and word not in stop_words]\n",
    "    for doc in documents\n",
    "]\n",
    "print(texts)\n",
    "print()\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d276b6-61bf-4ef3-be4f-991f96abc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.058*\"user\" + 0.047*\"response\" + 0.045*\"relation\" + 0.044*\"time\" + 0.044*\"measurement\" + 0.043*\"error\" + 0.042*\"perceived\" + 0.039*\"trees\" + 0.038*\"well\" + 0.037*\"widths\"\n",
      "Topic 1: 0.140*\"system\" + 0.072*\"user\" + 0.071*\"eps\" + 0.048*\"response\" + 0.048*\"time\" + 0.045*\"survey\" + 0.045*\"computer\" + 0.045*\"human\" + 0.044*\"testing\" + 0.044*\"opinion\"\n",
      "Topic 2: 0.083*\"graph\" + 0.080*\"trees\" + 0.053*\"minors\" + 0.039*\"survey\" + 0.039*\"binary\" + 0.038*\"generation\" + 0.038*\"intersection\" + 0.038*\"random\" + 0.038*\"unordered\" + 0.038*\"paths\"\n",
      "New document topic distribution: [(0, 0.11525135), (1, 0.7552332), (2, 0.12951544)]\n"
     ]
    }
   ],
   "source": [
    "num_topics = 3\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(num_topics):\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "new_doc = \"Human computer interaction\"\n",
    "new_bow = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(\"New document topic distribution:\", lda_model.get_document_topics(new_bow))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl",
   "language": "python",
   "name": "bdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
